{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель определения токсичных комментариев\n",
    "**Проект №12 Яндекс.Практикум - Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта\n",
    "\n",
    "**Исходные данные:**\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Цель проекта:**\n",
    "\n",
    "Разработать модель классификации комментариев на позитивные и негативные.\n",
    "\n",
    "**Условия задачи:**\n",
    "\n",
    "Значение метрики качества **F1** не меньше **0.75**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Структура проекта\n",
    "* [1. Загрузка и анализ данных](#start)\n",
    "* [2. Подготовка данных](#preparation)\n",
    "* [3. Обучение модели](#model)\n",
    "* [4. Тестирование](#testing)\n",
    "* [5. Выводы](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"start\"></a>\n",
    "## 1. Загрузка и анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import stopwords \n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sergio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sergio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sergio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sergio\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузим данные в DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитан файл с данными: \"./datasets/toxic_comments.csv\"\n"
     ]
    }
   ],
   "source": [
    "dataset = 'toxic_comments.csv'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(f'../datasets/{dataset}', sep=',')\n",
    "    print(f'Прочитан файл с данными: \"./datasets/{dataset}\"')\n",
    "except:\n",
    "    try:\n",
    "        data = pd.read_csv(f'/datasets/{dataset}', sep=',') # yandex.praktikum\n",
    "        print(f'Прочитан файл с данными: \"/datasets/{dataset}\"')\n",
    "    except Exception as err:\n",
    "        print(repr(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Описание данных:\n",
    "* text - текст комментария\n",
    "* toxic — целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во текстов класса 0: 143346 (89.83%)\n",
      "Кол-во текстов класса 1: 16225 (10.17%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Кол-во текстов класса 0: {data['toxic'].value_counts()[0]} ({(data['toxic'].value_counts()[0]/data.shape[0])*100:.2f}%)\")\n",
    "print(f\"Кол-во текстов класса 1: {data['toxic'].value_counts()[1]} ({(data['toxic'].value_counts()[1]/data.shape[0])*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* отсутствуют пропуски в данных\n",
    "* классы несбалансированы, учтём это при обучении моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preparation\"></a>\n",
    "## 2. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматиизируем текст с помощью библиотек **spacy** и **TextBlob**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функции лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob lemmatizer\n",
    "def lemmatize_tblob(text):\n",
    "    sentence = TextBlob(text)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sentence.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy lemmatizer\n",
    "def lemmatize_spacy(text, lemmatizer):\n",
    "    doc = lemmatizer(text)\n",
    "    lemm_text = \" \".join([token.lemma_ for token in doc])\n",
    "        \n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция очистки текста (оставляет только буквы, кавычки и пробелы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear(text):\n",
    "    cleaned = re.sub(r\"[^a-zA-Z\\' ]\", ' ', text)\n",
    "    return \" \".join(cleaned.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['lemm_tblob'] = data['text'].apply(lemmatize_tblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "data['lemm_spacy'] = data['text'].apply(lemmatize_spacy, lemmatizer=sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим лемматизированных текст от лишних символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.21 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_tblob</th>\n",
       "      <th>lemm_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits make under my userna...</td>\n",
       "      <td>Explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww He match this background colour I 'm see...</td>\n",
       "      <td>D'aww he match this background colour I be see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I 'm really not try to edit war It 's ...</td>\n",
       "      <td>hey man I be really not try to edit war it be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I ca n't make any real suggestion on impr...</td>\n",
       "      <td>More I ca n't make any real suggestion on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir be my hero Any chance you remember wha...</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And for the second time of ask when your view ...</td>\n",
       "      <td>and for the second time of ask when your view ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>You should be ashamed of yourself That be a ho...</td>\n",
       "      <td>you should be ashamed of yourself that be a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "      <td>spitzer Umm there s no actual article for pros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And it look like it be actually you who put on...</td>\n",
       "      <td>and it look like it be actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really do n't think you understand I com...</td>\n",
       "      <td>and I really do n't think you understand I com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                               lemm_tblob  \\\n",
       "0       Explanation Why the edits make under my userna...   \n",
       "1       D'aww He match this background colour I 'm see...   \n",
       "2       Hey man I 'm really not try to edit war It 's ...   \n",
       "3       More I ca n't make any real suggestion on impr...   \n",
       "4       You sir be my hero Any chance you remember wha...   \n",
       "...                                                   ...   \n",
       "159566  And for the second time of ask when your view ...   \n",
       "159567  You should be ashamed of yourself That be a ho...   \n",
       "159568  Spitzer Umm theres no actual article for prost...   \n",
       "159569  And it look like it be actually you who put on...   \n",
       "159570  And I really do n't think you understand I com...   \n",
       "\n",
       "                                               lemm_spacy  \n",
       "0       Explanation why the edit make under my usernam...  \n",
       "1       D'aww he match this background colour I be see...  \n",
       "2       hey man I be really not try to edit war it be ...  \n",
       "3       More I ca n't make any real suggestion on impr...  \n",
       "4       you sir be my hero any chance you remember wha...  \n",
       "...                                                   ...  \n",
       "159566  and for the second time of ask when your view ...  \n",
       "159567  you should be ashamed of yourself that be a ho...  \n",
       "159568  spitzer Umm there s no actual article for pros...  \n",
       "159569  and it look like it be actually you who put on...  \n",
       "159570  and I really do n't think you understand I com...  \n",
       "\n",
       "[159571 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['lemm_tblob'] = data['lemm_tblob'].apply(clear)\n",
    "data['lemm_spacy'] = data['lemm_spacy'].apply(clear)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you sir be my hero any chance you remember what page that be on\n",
      "You sir be my hero Any chance you remember what page that 's on\n",
      "congratulation from I as well use the tool well talk\n",
      "Congratulations from me a well use the tool well talk\n",
      "COCKSUCKER before you pis around on my work\n",
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "alignment on this subject and which be contrary to those of DuLithgow\n",
      "alignment on this subject and which be contrary to those of DuLithgow\n",
      "bbq be a man and let discuss it maybe over the phone\n",
      "bbq be a man and let discuss it maybe over the phone\n"
     ]
    }
   ],
   "source": [
    "print(data['lemm_spacy'][4])\n",
    "print(data['lemm_tblob'][4])\n",
    "print(data['lemm_spacy'][5])\n",
    "print(data['lemm_tblob'][5])\n",
    "print(data['lemm_spacy'][6])\n",
    "print(data['lemm_tblob'][6])\n",
    "print(data['lemm_spacy'][9])\n",
    "print(data['lemm_tblob'][9])\n",
    "print(data['lemm_spacy'][11])\n",
    "print(data['lemm_tblob'][11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* лемматизировали тексты используя библиотеки **spacy** и **TextBlob**\n",
    "* для **TextBlob** применили технику POS-tag (part-of-speech), в **spacy** она используется по умолчанию\n",
    "* значимых отличий в лемматизированных текстах разными библиотеками не замечено\n",
    "* лемматизация с **spacy** работает незначительно быстрее, чем с **TextBlob**\n",
    "* сравним на обученных моделях есть ли различия в качестве при использования лемматизированных текстов используя **spacy** и **TextBlob**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 3. Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на тестовую и тренировочную выборку в пропорции 4:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic']\n",
    "# Do not use extra space\n",
    "corpus_train, corpus_test, target_train, target_test = train_test_split(data['lemm_spacy'].values.astype('U'), target, test_size=0.2, stratify=target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим матрицу оценки важности слов, рассчитав для каждого слова TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер массива TF-IDF: (127656, 138588)\n"
     ]
    }
   ],
   "source": [
    "count_vect = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf  = count_vect.fit_transform(corpus_train) \n",
    "print(\"Размер массива TF-IDF:\", tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['toxic']\n",
    "# Do not use extra space\n",
    "corpus_train_tblob, corpus_test_tblob, target_train_tblob, target_test_tblob = train_test_split(data['lemm_tblob'].values.astype('U'), target, test_size=0.2, stratify=target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер массива TF-IDF: (127656, 138588)\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "count_vect_tblob = TfidfVectorizer(stop_words=stop_words)\n",
    "tf_idf_tblob  = count_vect_tblob.fit_transform(corpus_train) \n",
    "print(\"Размер массива TF-IDF:\", tf_idf_tblob.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 14min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.005,\n",
       "                       class_weight={0: 1, 1: 8}, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters selected on smaller amount of data \n",
    "model = RandomForestClassifier(ccp_alpha=0.005,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "parameters = {'max_depth' : [None, 30],\n",
    "              'class_weight' : [None, {0: 1, 1: 5}, {0: 1, 1: 8}]}\n",
    "\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(tf_idf, target_train)\n",
    "model_rfc = clf.best_estimator_\n",
    "model_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим F1 и баланс классов на обучающей выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08057362507392077\n",
      "{0: 127108, 1: 548}\n"
     ]
    }
   ],
   "source": [
    "predicted = model_rfc.predict(tf_idf)\n",
    "f1 = f1_score(target_train, predicted)\n",
    "print(f1)\n",
    "\n",
    "unique, counts = np.unique(predicted, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={0: 1, 1: 5}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                   random_state=91, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs',\n",
    "                           n_jobs=-1,\n",
    "                           random_state=91)\n",
    "\n",
    "parameters = {'class_weight': [{0: 1, 1: 5}, {0: 1, 1: 7}]}\n",
    "\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(tf_idf, target_train)\n",
    "model_logreg = clf.best_estimator_\n",
    "model_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим F1 и баланс классов на обучающей выборке "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742113422504237\n",
      "{0: 112899, 1: 14757}\n"
     ]
    }
   ],
   "source": [
    "predicted = model_logreg.predict(tf_idf)\n",
    "f1 = f1_score(target_train, predicted)\n",
    "print(f1)\n",
    "\n",
    "unique, counts = np.unique(predicted, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выводы:\n",
    "* подобраны наилучшие гиперпараметры для **Random Forrest** и для **Logistic Regression**\n",
    "* на Random Forrest не удалось получить приемлимое значение F1 даже на обучающих данных, при этом при таком большом количестве параметро обучается очень долго\n",
    "* Logistic Regression немного переобучается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "## 4. Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем TF-IDF для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер массива TF-IDF: (31915, 138588)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_test = count_vect.transform(corpus_test) \n",
    "print(\"Размер массива TF-IDF:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score Random Forrest: 0.09117647058823529\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_rfc.predict(tf_idf_test)\n",
    "print(f\"F1 score Random Forrest: {f1_score(target_test, predicted_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score Logistic Regression: 0.7809917355371901\n"
     ]
    }
   ],
   "source": [
    "predicted_test = model_logreg.predict(tf_idf_test)\n",
    "print(f\"F1 score Logistic Regression: {f1_score(target_test, predicted_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним есть ли разница по сравнению с лемматизированных текстом с помощью TextBLob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер массива TF-IDF: (31915, 138588)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_test_tblob = count_vect_tblob.transform(corpus_test_tblob) \n",
    "print(\"Размер массива TF-IDF:\", tf_idf_test_tblob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score Logistic Regression (TextBlob): 0.7809917355371901\n"
     ]
    }
   ],
   "source": [
    "predicted_test_tblob = model_logreg.predict(tf_idf_test_tblob)\n",
    "print(f\"F1 score Logistic Regression (TextBlob): {f1_score(target_test, predicted_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 5. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* лемматизировали текст используя библиотеки **spacy** и **TextBlob**\n",
    "* сравнили результаты модели классификации на леммах сделанных **spacy** и **TextBlob**, и выявили, что отличий нет\n",
    "* обучили модели Random Forrest и Logistic Regression\n",
    "* обучали модели, учитывая дисбаланс классов, и подобрали наилучшие гиперпараметры, использоу Grid Search\n",
    "* выявили, что для задачи классификации текстов лучше подходит модель Logistic Regression\n",
    "* на тестовой выборке получили значение F1 = 0.78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
